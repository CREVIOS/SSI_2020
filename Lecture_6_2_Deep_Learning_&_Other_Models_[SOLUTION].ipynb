{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 6.2: Deep Learning & Other Models [SOLUTION]",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CREVIOS/SSI_2020/blob/master/Lecture_6_2_Deep_Learning_%26_Other_Models_%5BSOLUTION%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Eou2YfoejB",
        "colab_type": "text"
      },
      "source": [
        "# Codealong - SVM and Naive Bayes\n",
        "\n",
        "In this codealong, we'll be using sklearn's SVM and Naive Bayes classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdIK_5iAoqwT",
        "colab_type": "text"
      },
      "source": [
        "## 0. Setup\n",
        "\n",
        "First, run the following code blocks to set up our imports and load our data (the MNIST dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qJlmNWIb2yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUjYqKIDseAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load mnist data\n",
        "data_train = pd.read_csv(\"sample_data/mnist_train_small.csv\")\n",
        "display(data_train)\n",
        "data_test = pd.read_csv(\"sample_data/mnist_test.csv\")\n",
        "display(data_test)\n",
        "data_train = data_train.loc[:4000, :].to_numpy()\n",
        "# display(data_train)\n",
        "data_test = data_test.loc[:1000, :].to_numpy()\n",
        "# display(data_test)\n",
        "\n",
        "# Split test into val and test\n",
        "split_index = data_test.shape[0] // 2\n",
        "data_val, data_test = np.split(data_test, [split_index])\n",
        "\n",
        "# Split into X_train, y_train, X_val, y_val, X_test, and y_test\n",
        "X_train = data_train[:, 1:]\n",
        "y_train = data_train[:, 0]\n",
        "X_val = data_val[:, 1:]\n",
        "y_val = data_val[:, 0]\n",
        "X_test = data_test[:, 1:]\n",
        "y_test = data_test[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9T_agzxswQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "row = X_train[5].reshape((28, 28))\n",
        "plt.imshow(row, cmap=\"Greys\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBWeJmHlpHM_",
        "colab_type": "text"
      },
      "source": [
        "## 1. SVM Classifier\n",
        "\n",
        "Write code to create an SVM object, and fit it on our data. Then, predict on the val data and get an F1 Score. Google \"sklearn SVM classifier\" to try and find the documentation yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHvDoIxps06e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Create and fit an SVM\n",
        "import sklearn.svm\n",
        "\n",
        "svm = sklearn.svm.SVC()\n",
        "svm.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjPTextDs7ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Predict with the SVM and report the F1 Score\n",
        "yhat_val = svm.predict(X_val)\n",
        "print(sklearn.metrics.f1_score(y_val, yhat_val, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ISWLrshUvA",
        "colab_type": "text"
      },
      "source": [
        "## 2. Naive Bayes Classifier\n",
        "\n",
        "Write code to create a Gaussian Naive Bayes classifier object, and fit it on our data. Then, predict on the val data and get an F1 Score. Google \"sklearn naive bayes\" to try and find the documentation yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfYUuUnQs9jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Create and fit a Gaussian Naive Bayes classifier\n",
        "import sklearn.naive_bayes\n",
        "\n",
        "gnb = sklearn.naive_bayes.GaussianNB()\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koJ3fgSXs00F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Predict with the Gaussian Naive Bayes model and report the F1 Score\n",
        "yhat_val = gnb.predict(X_val)\n",
        "print(sklearn.metrics.f1_score(y_val, yhat_val, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aw6ko0PtuJe",
        "colab_type": "text"
      },
      "source": [
        "# Codealong - Deep Learning\n",
        "\n",
        "Write code to create an MLP classifier object, and fit it on our data. Then, predict on the val data (AND the train set) and get an F1 Score for both. Google \"sklearn neural network\" to try and find the documentation yourself!\n",
        "\n",
        "Note how long it takes, and expirement with different values of alpha! To start, 0.2 is usually good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bq9rDT5tiHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Create and fit an MLP classifier\n",
        "import sklearn.neural_network\n",
        "\n",
        "nn = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100, 50), alpha=0.2)\n",
        "nn.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuEPXiIhuGTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Predict with the MLP model (on both the val and train set) and report the F1 Score\n",
        "yhat_val = nn.predict(X_val)\n",
        "print(sklearn.metrics.f1_score(y_val, yhat_val, average='macro'))\n",
        "\n",
        "yhat_train = nn.predict(X_train)\n",
        "print(sklearn.metrics.f1_score(y_train, yhat_train, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}